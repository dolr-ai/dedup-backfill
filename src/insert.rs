use std::{
    collections::BTreeMap,
    sync::{
        Arc,
        atomic::{AtomicU64, Ordering},
    },
    time::Duration,
};

use anyhow::Context;
use chrono::Utc;
use kv::Json;
use spacetimedb_sdk::Status;
use yral_spacetime_bindings::autogenerated::dedup_index::{self, add};

use crate::{
    progress::styled_bar,
    tables::{
        InsertTaskState, VideoHashFromBQ, VideoId, get_hash_bucket, get_task_bucket, open_store,
    },
};

pub async fn insert_to_stdb(cutoff: chrono::DateTime<Utc>, token: String) -> anyhow::Result<()> {
    let store = open_store()?;
    let video_hashes = get_hash_bucket(&store)?;
    let results = get_task_bucket(&store)?;

    let mut work_items = BTreeMap::new();
    let mut skipped = 0;
    let mut total = 0;
    for hash in video_hashes.iter() {
        total += 1;
        let hash = hash.context("Couldn't read from kv")?;

        let key: VideoId = hash.key()?;
        let value = match results.get(&key)? {
            Some(Json(value)) => value,
            None => Default::default(),
        };

        if matches!(value, InsertTaskState::Inserted) {
            skipped += 1;
            continue;
        }

        let Json(value) = hash.value().expect("this doesn't really fail");

        // every video that _after_ and _including_ cutoff is to be excluded
        if value.timestamp >= cutoff.into() {
            skipped += 1;
            continue;
        }

        work_items.insert(key, value);
    }

    println!("total id = {total}");
    if skipped > 0 {
        println!("but, {skipped} were skipped. leaving {}", work_items.len());
    }

    let bar = styled_bar(work_items.len() as u64);
    bar.enable_steady_tick(Duration::from_millis(100));

    // open connectiont to stdb
    // on each callback, map reducer status to insert task state and save
    // when counter hits expected len, regardless of status, send signal over oneshot
    // iterate and call reducer. fire and forget
    // wait on signal

    let (result_tx, mut result_rx) = tokio::sync::mpsc::unbounded_channel();
    let result_tx = Arc::new(result_tx);

    let ctx = dedup_index::DbConnection::builder()
        .with_uri("https://maincloud.spacetimedb.com/")
        .with_token(Some(token))
        .with_module_name("yral-dedup-index")
        .build()?;

    let ctx = Arc::new(ctx);
    let ticker_ctx = ctx.clone();
    tokio::spawn(async move {
        ticker_ctx.run_async().await.unwrap();
    });

    let counter = AtomicU64::new(0);
    let total = work_items.len() as u64;
    let cb_bar = bar.clone();
    ctx.reducers.on_add(move |ev, _, video_id, _| {
        let state = match ev.event.status {
            Status::Committed => InsertTaskState::Inserted,
            Status::Failed(ref err) => {
                cb_bar.println(format!("insertion error from stdb: {err}"));
                InsertTaskState::ToBeInserted
            }
            Status::OutOfEnergy => {
                cb_bar.println("stdb ran out of energy? :/");
                InsertTaskState::ToBeInserted
            }
        };

        result_tx.send((video_id.to_owned(), state)).unwrap();
    });

    for (
        video_id,
        VideoHashFromBQ {
            video_hash,
            timestamp,
        },
    ) in work_items
    {
        ctx.reducers.add(video_hash, video_id, timestamp.into())?;
    }

    while let Some((video_id, state)) = result_rx.recv().await {
        counter.fetch_add(1, Ordering::Release);
        results
            .set(&video_id, &Json(state))
            .expect("yeah this never fails tbh");

        bar.inc(1);
        if counter.load(Ordering::Acquire) == total {
            break;
        }
    }

    bar.finish();
    Ok(())
}
